{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import getpass\nfrom pathlib import Path\nfrom typing import Any, Callable, List, Optional, Sequence, Tuple, Union\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom scipy.interpolate import interp1d\nfrom sklearn.preprocessing import RobustScaler\nfrom torch import LongTensor, Tensor\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nfrom transformers import get_cosine_schedule_with_warmup\n\nKERNEL = False if getpass.getuser() == \"anjum\" else True\nCOMP_NAME = \"icecube-neutrinos-in-deep-ice\"\n\nif not KERNEL:\n    INPUT_PATH = Path(f\"/mnt/storage_dimm2/kaggle_data/{COMP_NAME}\")\n    OUTPUT_PATH = Path(f\"/mnt/storage_dimm2/kaggle_output/{COMP_NAME}\")\n    MODEL_CACHE = Path(\"/mnt/storage/model_cache/torch\")\n    TRANSPARENCY_PATH = INPUT_PATH / \"ice_transparency.txt\"\nelse:\n    INPUT_PATH = Path(f\"/kaggle/input/{COMP_NAME}\")\n    MODEL_CACHE = None\n    TRANSPARENCY_PATH = \"/kaggle/input/icecubetransparency/ice_transparency.txt\"\n\n    # Install packages\n    import subprocess\n\n    whls = [\n        \"/kaggle/input/pytorchgeometric/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\",\n        \"/kaggle/input/pytorchgeometric/torch_scatter-2.1.0-cp37-cp37m-linux_x86_64.whl\",\n        \"/kaggle/input/pytorchgeometric/torch_sparse-0.6.16-cp37-cp37m-linux_x86_64.whl\",\n        \"/kaggle/input/pytorchgeometric/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl\",\n        \"/kaggle/input/pytorchgeometric/torch_geometric-2.2.0-py3-none-any.whl\",\n        \"/kaggle/input/pytorchgeometric/ruamel.yaml-0.17.21-py3-none-any.whl\",\n    ]\n\n    for w in whls:\n        print(\"Installing\", w)\n        subprocess.call([\"pip\", \"install\", w, \"--no-deps\", \"--upgrade\"])\n\n    import sys\n    sys.path.append(\"/kaggle/input/graphnet/graphnet-main/src\")\n\nfrom graphnet.models.graph_builders import KNNGraphBuilder\nfrom graphnet.models.task.reconstruction import (\n    AzimuthReconstructionWithKappa,\n    ZenithReconstruction,\n)\nfrom graphnet.training.loss_functions import VonMisesFisher2DLoss\nfrom graphnet.models.gnn.gnn import GNN\nfrom graphnet.models.utils import calculate_xyzt_homophily\nfrom graphnet.utilities.config import save_model_config\n\nfrom torch_geometric.data import Data, Dataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import EdgeConv\nfrom torch_geometric.nn.pool import knn_graph\nfrom torch_geometric.typing import Adj\nfrom torch_scatter import scatter_max, scatter_mean, scatter_min, scatter_sum\n\nGLOBAL_POOLINGS = {\n    \"min\": scatter_min,\n    \"max\": scatter_max,\n    \"sum\": scatter_sum,\n    \"mean\": scatter_mean,\n}\n\n_dtype = {\n    \"batch_id\": \"int16\",\n    \"event_id\": \"int64\",\n}","metadata":{"_uuid":"632c42d7-0e51-42ee-8205-cc7fec9d0c56","_cell_guid":"7e3ab8b8-8781-4d27-958b-ea47012eb172","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-03-21T05:07:17.079768Z","iopub.execute_input":"2023-03-21T05:07:17.080177Z","iopub.status.idle":"2023-03-21T05:09:36.876154Z","shell.execute_reply.started":"2023-03-21T05:07:17.080095Z","shell.execute_reply":"2023-03-21T05:09:36.875073Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\nProcessing /kaggle/input/pytorchgeometric/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-cluster\nSuccessfully installed torch-cluster-1.6.0\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/torch_scatter-2.1.0-cp37-cp37m-linux_x86_64.whl\nProcessing /kaggle/input/pytorchgeometric/torch_scatter-2.1.0-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.0\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/torch_sparse-0.6.16-cp37-cp37m-linux_x86_64.whl\nProcessing /kaggle/input/pytorchgeometric/torch_sparse-0.6.16-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-sparse\nSuccessfully installed torch-sparse-0.6.16\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl\nProcessing /kaggle/input/pytorchgeometric/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-spline-conv\nSuccessfully installed torch-spline-conv-1.2.1\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/torch_geometric-2.2.0-py3-none-any.whl\nProcessing /kaggle/input/pytorchgeometric/torch_geometric-2.2.0-py3-none-any.whl\nInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.2.0\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/ruamel.yaml-0.17.21-py3-none-any.whl\nProcessing /kaggle/input/pytorchgeometric/ruamel.yaml-0.17.21-py3-none-any.whl\nInstalling collected packages: ruamel.yaml\nSuccessfully installed ruamel.yaml-0.17.21\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-21 05:09:36 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230321-050936.log\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!cat /kaggle/input/icecubetransparency/ice_transparency.txt","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:36.878609Z","iopub.execute_input":"2023-03-21T05:09:36.879775Z","iopub.status.idle":"2023-03-21T05:09:37.896975Z","shell.execute_reply.started":"2023-03-21T05:09:36.879722Z","shell.execute_reply":"2023-03-21T05:09:37.895685Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"depth scattering_len absorption_len\n1398.4 13.2 45.1\n1408.4 14.0 48.6\n1418.4 14.7 53.2\n1428.4 17.0 57.6\n1438.4 16.0 57.6\n1448.4 14.4 52.2\n1458.4 16.0 60.1\n1468.4 20.8 74.6\n1478.4 26.7 96.6\n1488.4 34.7 110.5\n1498.4 39.7 135.6\n1508.5 38.7 134.7\n1518.6 27.8 98.2\n1528.7 16.6 64.7\n1538.8 13.7 48.5\n1548.7 13.5 44.3\n1558.7 15.7 54.4\n1568.5 15.7 56.7\n1578.5 14.7 52.1\n1588.5 17.6 60.7\n1598.5 21.6 72.7\n1608.5 24.0 78.9\n1618.5 20.0 68.7\n1628.5 17.8 66.6\n1638.5 28.9 100.0\n1648.4 36.9 128.6\n1658.4 42.1 148.2\n1668.4 46.5 165.7\n1678.5 45.4 156.0\n1688.5 39.1 138.5\n1698.5 30.6 113.9\n1708.5 26.5 90.2\n1718.5 19.3 73.5\n1728.5 20.8 75.9\n1738.5 20.1 67.8\n1748.5 20.3 68.6\n1758.5 24.5 83.8\n1768.5 33.5 119.5\n1778.5 36.2 121.6\n1788.5 35.4 108.3\n1798.5 32.3 113.4\n1808.5 40.2 139.1\n1818.4 44.7 148.1\n1828.4 34.5 122.8\n1838.4 30.6 113.8\n1848.4 27.5 89.9\n1858.4 19.7 71.7\n1868.5 21.4 70.6\n1878.5 28.8 95.9\n1888.5 38.3 116.5\n1898.5 38.4 143.6\n1908.5 44.2 169.4\n1918.5 50.5 178.0\n1928.5 46.6 156.5\n1938.5 36.8 135.3\n1948.5 26.7 103.9\n1958.5 20.3 75.2\n1968.5 17.4 66.2\n1978.5 16.1 53.7\n1988.4 9.4 33.6\n1998.4 10.6 36.2\n2008.4 13.2 44.0\n2018.5 10.9 40.4\n2028.5 6.8 24.9\n2038.5 5.5 20.1\n2048.5 5.0 17.9\n2058.5 7.2 28.4\n2068.5 9.8 34.4\n2078.5 12.2 41.6\n2088.5 21.1 84.4\n2098.5 54.3 173.1\n2108.5 50.5 180.8\n2118.4 33.5 116.7\n2128.4 34.6 120.4\n2138.4 48.4 164.4\n2148.4 53.2 172.8\n2158.3 46.3 149.2\n2168.3 32.9 108.4\n2178.3 27.4 91.1\n2188.2 30.5 98.9\n2198.2 28.9 94.0\n2208.2 35.1 113.1\n2218.2 39.9 134.8\n2228.2 48.0 154.1\n2238.3 53.3 157.6\n2248.3 54.8 180.5\n2258.3 57.9 179.7\n2268.2 61.1 185.2\n2278.2 76.8 227.2\n2288.1 79.0 220.8\n2298.0 75.6 223.9\n2308.0 75.3 256.6\n2318.0 78.0 264.4\n2328.0 59.4 193.7\n2338.0 51.8 159.1\n2348.0 32.9 118.7\n2357.9 23.9 86.2\n2367.8 28.6 104.0\n2377.8 32.5 119.7\n2387.8 44.5 140.6\n2397.9 56.9 203.5\n2408.0 57.5 201.8\n2418.0 54.3 178.2\n2428.1 61.3 206.0\n2438.1 68.8 205.2\n2448.2 77.6 232.1\n2458.2 79.8 259.4\n2468.3 89.4 276.1\n2478.4 80.7 244.3\n2488.4 56.7 185.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# models.py\nclass IceCubeModel(pl.LightningModule):\n    def __init__(\n        self,\n        model_name: str = \"DynEdge\",\n        learning_rate: float = 0.001,\n        weight_decay: float = 0.01,\n        warmup: float = 0.1,\n        T_max: int = 1000,\n        nb_inputs: int = 8,\n        nearest_neighbours: int = 8,\n        **kwargs,\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n\n        self.loss_fn_azi = VonMisesFisher2DLoss()\n        self.loss_fn_zen = nn.L1Loss()\n        # self.loss_fn_cos = CosineLoss()\n\n        self.model = DynEdge(\n            nb_inputs=nb_inputs,\n            nb_neighbours=nearest_neighbours,\n            global_pooling_schemes=[\"min\", \"max\", \"mean\", \"sum\"],\n            features_subset=slice(0, 4),  # NN search using xyzt\n        )\n        # self.head = nn.Linear(self.model.nb_outputs, 2)\n        self.azimuth_task = AzimuthReconstructionWithKappa(\n            hidden_size=self.model.nb_outputs,\n            loss_function=self.loss_fn_azi,\n            target_labels=[\"azimuth\", \"kappa\"],\n        )\n\n        self.zenith_task = ZenithReconstruction(\n            hidden_size=self.model.nb_outputs,\n            loss_function=self.loss_fn_zen,\n            target_labels=[\"zenith\"],\n        )\n        # self.norm = nn.BatchNorm1d(self.model.nb_outputs)\n\n    def forward(self, x):\n        emb = self.model(x)\n        # emb = self.norm(emb)\n        azi_out = self.azimuth_task(emb)\n        zen_out = self.zenith_task(emb)\n\n        return azi_out, zen_out\n\n    def training_step(self, batch, batch_idx):\n        pred_azi, pred_zen = self.forward(batch)\n\n        target = batch.y.reshape(-1, 2)\n\n        # weight = 1 - np.exp(-self.global_step / (self.hparams.T_max))\n        loss_azi = self.loss_fn_azi(pred_azi, target)\n        loss_zen = self.loss_fn_zen(pred_zen, target[:, -1].unsqueeze(-1))\n        loss = loss_azi + loss_zen\n\n        pred_angles = torch.stack([pred_azi[:, 0], pred_zen[:, 0]], dim=1)\n        # metric = angular_dist_score(pred_angles, target)\n\n        loss_cos = self.loss_fn_cos(pred_angles, target)\n\n        if self.current_epoch > 0:\n            loss += loss_cos\n\n        self.log_dict({\"loss/train_step\": loss})\n        return {\"loss\": loss}\n\n    def training_epoch_end(self, training_step_outputs):\n        avg_loss = torch.stack([x[\"loss\"] for x in training_step_outputs]).mean()\n        self.log(\"loss/train\", avg_loss, sync_dist=True)\n\n    def validation_step(self, batch, batch_idx):\n        pred_azi, pred_zen = self.forward(batch)\n\n        target = batch.y.reshape(-1, 2)\n\n        # weight = 1 - np.exp(-self.global_step / (self.hparams.T_max))\n        loss_azi = self.loss_fn_azi(pred_azi, target)\n        loss_zen = self.loss_fn_zen(pred_zen, target[:, -1].unsqueeze(-1))\n        loss = loss_azi + loss_zen\n\n        pred_angles = torch.stack([pred_azi[:, 0], pred_zen[:, 0]], dim=1)\n        metric = angular_dist_score(pred_angles, target)\n\n        loss_cos = self.loss_fn_cos(pred_angles, target)\n\n        if self.current_epoch > 0:\n            loss += loss_cos\n\n        output = {\n            \"val_loss\": loss,\n            \"metric\": metric,\n            \"val_loss_azi\": loss_azi,\n            \"val_loss_zen\": loss_zen,\n            \"val_loss_cos\": loss_cos,\n        }\n\n        return output\n\n    def validation_epoch_end(self, outputs):\n        loss_val = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        loss_val_azi = torch.stack([x[\"val_loss_azi\"] for x in outputs]).mean()\n        loss_val_zen = torch.stack([x[\"val_loss_zen\"] for x in outputs]).mean()\n        val_loss_cos = torch.stack([x[\"val_loss_cos\"] for x in outputs]).mean()\n        metric = torch.stack([x[\"metric\"] for x in outputs]).mean()\n\n        self.log_dict(\n            {\"loss/valid\": loss_val, \"metric\": metric},\n            prog_bar=True,\n            sync_dist=True,\n        )\n        self.log_dict(\n            {\n                \"loss/valid_azi\": loss_val_azi,\n                \"loss/valid_zen\": loss_val_zen,\n                \"loss/valid_cos\": val_loss_cos,\n            },\n            prog_bar=False,\n            sync_dist=True,\n        )\n\n    def configure_optimizers(self):\n        parameters = add_weight_decay(\n            self,\n            self.hparams.weight_decay,\n            skip_list=[\"bias\", \"LayerNorm.bias\"],  # , \"LayerNorm.weight\"],\n        )\n\n        opt = torch.optim.AdamW(parameters, lr=self.hparams.learning_rate)\n\n        sch = get_cosine_schedule_with_warmup(\n            opt,\n            # num_warmup_steps=int(0.1 * self.hparams.T_max),\n            num_warmup_steps=int(0 * self.hparams.T_max),\n            num_training_steps=self.hparams.T_max,\n            num_cycles=0.5,  # 1,\n            last_epoch=-1,\n        )\n\n        return {\n            \"optimizer\": opt,\n            \"lr_scheduler\": {\"scheduler\": sch, \"interval\": \"step\"},\n        }","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:37.898789Z","iopub.execute_input":"2023-03-21T05:09:37.899150Z","iopub.status.idle":"2023-03-21T05:09:37.924156Z","shell.execute_reply.started":"2023-03-21T05:09:37.899111Z","shell.execute_reply":"2023-03-21T05:09:37.923067Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# modules.py\nclass DynEdgeConv(EdgeConv, pl.LightningModule):\n    \"\"\"Dynamical edge convolution layer.\"\"\"\n\n    def __init__(\n        self,\n        nn: Callable,\n        aggr: str = \"max\",\n        nb_neighbors: int = 8,\n        features_subset: Optional[Union[Sequence[int], slice]] = None,\n        **kwargs: Any,\n    ):\n        \"\"\"Construct `DynEdgeConv`.\n        Args:\n            nn: The MLP/torch.Module to be used within the `EdgeConv`.\n            aggr: Aggregation method to be used with `EdgeConv`.\n            nb_neighbors: Number of neighbours to be clustered after the\n                `EdgeConv` operation.\n            features_subset: Subset of features in `Data.x` that should be used\n                when dynamically performing the new graph clustering after the\n                `EdgeConv` operation. Defaults to all features.\n            **kwargs: Additional features to be passed to `EdgeConv`.\n        \"\"\"\n        # Check(s)\n        if features_subset is None:\n            features_subset = slice(None)  # Use all features\n        assert isinstance(features_subset, (list, slice))\n\n        # Base class constructor\n        super().__init__(nn=nn, aggr=aggr, **kwargs)\n\n        # Additional member variables\n        self.nb_neighbors = nb_neighbors\n        self.features_subset = features_subset\n\n    def forward(\n        self, x: Tensor, edge_index: Adj, batch: Optional[Tensor] = None\n    ) -> Tensor:\n\n        \"\"\"Forward pass.\"\"\"\n        # Standard EdgeConv forward pass\n        x = super().forward(x, edge_index)\n\n        # Recompute adjacency\n        edge_index = knn_graph(\n            x=x[:, self.features_subset],\n            k=self.nb_neighbors,\n            batch=batch,\n        ).to(self.device)\n\n        return x, edge_index","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:37.926973Z","iopub.execute_input":"2023-03-21T05:09:37.927594Z","iopub.status.idle":"2023-03-21T05:09:37.940135Z","shell.execute_reply.started":"2023-03-21T05:09:37.927557Z","shell.execute_reply":"2023-03-21T05:09:37.939075Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class DynEdge(GNN):\n    \"\"\"DynEdge (dynamical edge convolutional) model.\"\"\"\n\n    @save_model_config\n    def __init__(\n        self,\n        nb_inputs: int,\n        *,\n        nb_neighbours: int = 8,\n        features_subset: Optional[Union[List[int], slice]] = None,\n        dynedge_layer_sizes: Optional[List[Tuple[int, ...]]] = None,\n        post_processing_layer_sizes: Optional[List[int]] = None,\n        readout_layer_sizes: Optional[List[int]] = None,\n        global_pooling_schemes: Optional[Union[str, List[str]]] = None,\n        add_global_variables_after_pooling: bool = False,\n    ):\n        \"\"\"Construct `DynEdge`.\n        Args:\n            nb_inputs: Number of input features on each node.\n            nb_neighbours: Number of neighbours to used in the k-nearest\n                neighbour clustering which is performed after each (dynamical)\n                edge convolution.\n            features_subset: The subset of latent features on each node that\n                are used as metric dimensions when performing the k-nearest\n                neighbours clustering. Defaults to [0,1,2].\n            dynedge_layer_sizes: The layer sizes, or latent feature dimenions,\n                used in the `DynEdgeConv` layer. Each entry in\n                `dynedge_layer_sizes` corresponds to a single `DynEdgeConv`\n                layer; the integers in the corresponding tuple corresponds to\n                the layer sizes in the multi-layer perceptron (MLP) that is\n                applied within each `DynEdgeConv` layer. That is, a list of\n                size-two tuples means that all `DynEdgeConv` layers contain a\n                two-layer MLP.\n                Defaults to [(128, 256), (336, 256), (336, 256), (336, 256)].\n            post_processing_layer_sizes: Hidden layer sizes in the MLP\n                following the skip-concatenation of the outputs of each\n                `DynEdgeConv` layer. Defaults to [336, 256].\n            readout_layer_sizes: Hidden layer sizes in the MLP following the\n                post-processing _and_ optional global pooling. As this is the\n                last layer(s) in the model, the last layer in the read-out\n                yields the output of the `DynEdge` model. Defaults to [128,].\n            global_pooling_schemes: The list global pooling schemes to use.\n                Options are: \"min\", \"max\", \"mean\", and \"sum\".\n            add_global_variables_after_pooling: Whether to add global variables\n                after global pooling. The alternative is to  added (distribute)\n                them to the individual nodes before any convolutional\n                operations.\n        \"\"\"\n        # Latent feature subset for computing nearest neighbours in DynEdge.\n        if features_subset is None:\n            features_subset = slice(0, 3)\n\n        # DynEdge layer sizes\n        if dynedge_layer_sizes is None:\n            dynedge_layer_sizes = [\n                (\n                    128,\n                    256,\n                ),\n                (\n                    336,\n                    256,\n                ),\n                (\n                    336,\n                    256,\n                ),\n                (\n                    336,\n                    256,\n                ),\n            ]\n\n        assert isinstance(dynedge_layer_sizes, list)\n        assert len(dynedge_layer_sizes)\n        assert all(isinstance(sizes, tuple) for sizes in dynedge_layer_sizes)\n        assert all(len(sizes) > 0 for sizes in dynedge_layer_sizes)\n        assert all(all(size > 0 for size in sizes) for sizes in dynedge_layer_sizes)\n\n        self._dynedge_layer_sizes = dynedge_layer_sizes\n\n        # Post-processing layer sizes\n        if post_processing_layer_sizes is None:\n            post_processing_layer_sizes = [\n                336,\n                256,\n            ]\n\n        assert isinstance(post_processing_layer_sizes, list)\n        assert len(post_processing_layer_sizes)\n        assert all(size > 0 for size in post_processing_layer_sizes)\n\n        self._post_processing_layer_sizes = post_processing_layer_sizes\n\n        # Read-out layer sizes\n        if readout_layer_sizes is None:\n            readout_layer_sizes = [\n                128,\n            ]\n\n        assert isinstance(readout_layer_sizes, list)\n        assert len(readout_layer_sizes)\n        assert all(size > 0 for size in readout_layer_sizes)\n\n        self._readout_layer_sizes = readout_layer_sizes\n\n        # Global pooling scheme(s)\n        if isinstance(global_pooling_schemes, str):\n            global_pooling_schemes = [global_pooling_schemes]\n\n        if isinstance(global_pooling_schemes, list):\n            for pooling_scheme in global_pooling_schemes:\n                assert (\n                    pooling_scheme in GLOBAL_POOLINGS\n                ), f\"Global pooling scheme {pooling_scheme} not supported.\"\n        else:\n            assert global_pooling_schemes is None\n\n        self._global_pooling_schemes = global_pooling_schemes\n\n        if add_global_variables_after_pooling:\n            assert self._global_pooling_schemes, (\n                \"No global pooling schemes were request, so cannot add global\"\n                \" variables after pooling.\"\n            )\n        self._add_global_variables_after_pooling = add_global_variables_after_pooling\n\n        # Base class constructor\n        super().__init__(nb_inputs, self._readout_layer_sizes[-1])\n\n        # Remaining member variables()\n        self._activation = torch.nn.GELU()\n        self._nb_inputs = nb_inputs\n        self._nb_global_variables = 5 + nb_inputs\n        self._nb_neighbours = nb_neighbours\n        self._features_subset = features_subset\n\n        self._construct_layers()\n\n    def _construct_layers(self) -> None:\n        \"\"\"Construct layers (torch.nn.Modules).\"\"\"\n        # Convolutional operations\n        nb_input_features = self._nb_inputs\n        if not self._add_global_variables_after_pooling:\n            nb_input_features += self._nb_global_variables\n\n        self._conv_layers = torch.nn.ModuleList()\n        nb_latent_features = nb_input_features\n        for sizes in self._dynedge_layer_sizes:\n            layers = []\n            layer_sizes = [nb_latent_features] + list(sizes)\n            for ix, (nb_in, nb_out) in enumerate(\n                zip(layer_sizes[:-1], layer_sizes[1:])\n            ):\n                if ix == 0:\n                    nb_in *= 2\n                layers.append(torch.nn.Linear(nb_in, nb_out))\n                layers.append(nn.BatchNorm1d(nb_out))\n                layers.append(self._activation)\n\n            conv_layer = DynEdgeConv(\n                torch.nn.Sequential(*layers),\n                aggr=\"add\",\n                nb_neighbors=self._nb_neighbours,\n                features_subset=self._features_subset,\n            )\n            self._conv_layers.append(conv_layer)\n\n            nb_latent_features = nb_out\n\n        # Post-processing operations\n        nb_latent_features = (\n            sum(sizes[-1] for sizes in self._dynedge_layer_sizes) + nb_input_features\n        )\n\n        post_processing_layers = []\n        layer_sizes = [nb_latent_features] + list(self._post_processing_layer_sizes)\n        for nb_in, nb_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n            post_processing_layers.append(torch.nn.Linear(nb_in, nb_out))\n            post_processing_layers.append(nn.BatchNorm1d(nb_out))\n            post_processing_layers.append(self._activation)\n\n        self._post_processing = torch.nn.Sequential(*post_processing_layers)\n\n        # Read-out operations\n        nb_poolings = (\n            len(self._global_pooling_schemes) if self._global_pooling_schemes else 1\n        )\n        nb_latent_features = nb_out * nb_poolings\n        if self._add_global_variables_after_pooling:\n            nb_latent_features += self._nb_global_variables\n\n        readout_layers = []\n        layer_sizes = [nb_latent_features] + list(self._readout_layer_sizes)\n        for nb_in, nb_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n            readout_layers.append(torch.nn.Linear(nb_in, nb_out))\n            readout_layers.append(nn.BatchNorm1d(nb_out))\n            readout_layers.append(self._activation)\n\n        self._readout = torch.nn.Sequential(*readout_layers)\n\n    def _global_pooling(self, x: Tensor, batch: LongTensor) -> Tensor:\n        \"\"\"Perform global pooling.\"\"\"\n        assert self._global_pooling_schemes\n        pooled = []\n        for pooling_scheme in self._global_pooling_schemes:\n            pooling_fn = GLOBAL_POOLINGS[pooling_scheme]\n            pooled_x = pooling_fn(x, index=batch, dim=0)\n            if isinstance(pooled_x, tuple) and len(pooled_x) == 2:\n                # `scatter_{min,max}`, which return also an argument, vs.\n                # `scatter_{mean,sum}`\n                pooled_x, _ = pooled_x\n            pooled.append(pooled_x)\n\n        return torch.cat(pooled, dim=1)\n\n    def _calculate_global_variables(\n        self,\n        x: Tensor,\n        edge_index: LongTensor,\n        batch: LongTensor,\n        *additional_attributes: Tensor,\n    ) -> Tensor:\n        \"\"\"Calculate global variables.\"\"\"\n        # Calculate homophily (scalar variables)\n        h_x, h_y, h_z, h_t = calculate_xyzt_homophily(x, edge_index, batch)\n\n        # Calculate mean features\n        global_means = scatter_mean(x, batch, dim=0)\n\n        # Add global variables\n        global_variables = torch.cat(\n            [\n                global_means,\n                h_x,\n                h_y,\n                h_z,\n                h_t,\n            ]\n            + [attr.unsqueeze(dim=1) for attr in additional_attributes],\n            dim=1,\n        )\n\n        return global_variables\n\n    def forward(self, data: Data) -> Tensor:\n        \"\"\"Apply learnable forward pass.\"\"\"\n        # Convenience variables\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n\n        global_variables = self._calculate_global_variables(\n            x,\n            edge_index,\n            batch,\n            torch.log10(data.n_pulses),\n        )\n\n        # Distribute global variables out to each node\n        if not self._add_global_variables_after_pooling:\n            distribute = (\n                batch.unsqueeze(dim=1) == torch.unique(batch).unsqueeze(dim=0)\n            ).type(torch.float)\n\n            global_variables_distributed = torch.sum(\n                distribute.unsqueeze(dim=2) * global_variables.unsqueeze(dim=0),\n                dim=1,\n            )\n\n            x = torch.cat((x, global_variables_distributed), dim=1)\n\n        # DynEdge-convolutions\n        skip_connections = [x]\n        for conv_layer in self._conv_layers:\n            x, edge_index = conv_layer(x, edge_index, batch)\n            skip_connections.append(x)\n\n        # Skip-cat\n        x = torch.cat(skip_connections, dim=1)\n\n        # Post-processing\n        x = self._post_processing(x)\n\n        # (Optional) Global pooling\n        if self._global_pooling_schemes:\n            x = self._global_pooling(x, batch=batch)\n            if self._add_global_variables_after_pooling:\n                x = torch.cat(\n                    [\n                        x,\n                        global_variables,\n                    ],\n                    dim=1,\n                )\n\n        # Read-out\n        x = self._readout(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:37.941845Z","iopub.execute_input":"2023-03-21T05:09:37.942429Z","iopub.status.idle":"2023-03-21T05:09:37.977701Z","shell.execute_reply.started":"2023-03-21T05:09:37.942394Z","shell.execute_reply":"2023-03-21T05:09:37.976701Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# utils.py\ndef add_weight_decay(\n    model,\n    weight_decay=1e-5,\n    skip_list=(\"bias\", \"bn\", \"LayerNorm.bias\", \"LayerNorm.weight\"),\n):\n    decay = []\n    no_decay = []\n    for name, param in model.named_parameters():\n        if not param.requires_grad:\n            continue  # frozen weights\n        if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list:\n            no_decay.append(param)\n        else:\n            decay.append(param)\n    return [\n        {\"params\": no_decay, \"weight_decay\": 0.0},\n        {\"params\": decay, \"weight_decay\": weight_decay},\n    ]\n\n\n# losses.py\ndef angular_dist_score(y_pred, y_true):\n    \"\"\"\n    calculate the MAE of the angular distance between two directions.\n    The two vectors are first converted to cartesian unit vectors,\n    and then their scalar product is computed, which is equal to\n    the cosine of the angle between the two vectors. The inverse\n    cosine (arccos) thereof is then the angle between the two itorchut vectors\n\n    # https://www.kaggle.com/code/sohier/mean-angular-error\n\n    Parameters:\n    -----------\n\n    y_pred : float (torch.Tensor)\n        Prediction array of [N, 2], where the second dim is azimuth & zenith\n    y_true : float (torch.Tensor)\n        Ground truth array of [N, 2], where the second dim is azimuth & zenith\n\n    Returns:\n    --------\n\n    dist : float (torch.Tensor)\n        mean over the angular distance(s) in radian\n    \"\"\"\n\n    az_true = y_true[:, 0]\n    zen_true = y_true[:, 1]\n\n    az_pred = y_pred[:, 0]\n    zen_pred = y_pred[:, 1]\n\n    # pre-compute all sine and cosine values\n    sa1 = torch.sin(az_true)\n    ca1 = torch.cos(az_true)\n    sz1 = torch.sin(zen_true)\n    cz1 = torch.cos(zen_true)\n\n    sa2 = torch.sin(az_pred)\n    ca2 = torch.cos(az_pred)\n    sz2 = torch.sin(zen_pred)\n    cz2 = torch.cos(zen_pred)\n\n    # scalar product of the two cartesian vectors (x = sz*ca, y = sz*sa, z = cz)\n    scalar_prod = sz1 * sz2 * (ca1 * ca2 + sa1 * sa2) + (cz1 * cz2)\n\n    # scalar product of two unit vectors is always between -1 and 1, this is against nummerical instability\n    # that might otherwise occure from the finite precision of the sine and cosine functions\n    scalar_prod = torch.clamp(scalar_prod, -1, 1)\n\n    # convert back to an angle (in radian)\n    return torch.mean(torch.abs(torch.arccos(scalar_prod)))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:37.980320Z","iopub.execute_input":"2023-03-21T05:09:37.980587Z","iopub.status.idle":"2023-03-21T05:09:37.995448Z","shell.execute_reply.started":"2023-03-21T05:09:37.980562Z","shell.execute_reply":"2023-03-21T05:09:37.994438Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# datasets.py\ndef ice_transparency(data_path, datum=1950):\n    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n    # Datum is from footnote 8 of page 29\n    df = pd.read_csv(data_path, delim_whitespace=True)\n    df[\"z\"] = df[\"depth\"] - datum\n    df[\"z_norm\"] = df[\"z\"] / 500\n    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n        df[[\"scattering_len\", \"absorption_len\"]]\n    )\n\n    # These are both roughly equivalent after scaling\n    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n    return f_scattering, f_absorption","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:37.998056Z","iopub.execute_input":"2023-03-21T05:09:37.998477Z","iopub.status.idle":"2023-03-21T05:09:38.006466Z","shell.execute_reply.started":"2023-03-21T05:09:37.998424Z","shell.execute_reply":"2023-03-21T05:09:38.005516Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class IceCubeSubmissionDataset(Dataset):\n    def __init__(\n        self,\n        batch_id,\n        event_ids,\n        sensor_df,\n        mode=\"test\",\n        pulse_limit=300,\n        transform=None,\n        pre_transform=None,\n        pre_filter=None,\n    ):\n        super().__init__(transform, pre_transform, pre_filter)\n        self.event_ids = event_ids\n        self.batch_df = pd.read_parquet(INPUT_PATH / mode / f\"batch_{batch_id}.parquet\")\n        self.sensor_df = sensor_df\n        self.pulse_limit = pulse_limit\n        self.f_scattering, self.f_absorption = ice_transparency(TRANSPARENCY_PATH)\n\n        self.batch_df[\"time\"] = (self.batch_df[\"time\"] - 1.0e04) / 3.0e4\n        self.batch_df[\"charge\"] = np.log10(self.batch_df[\"charge\"]) / 3.0\n        self.batch_df[\"auxiliary\"] = self.batch_df[\"auxiliary\"].astype(int) - 0.5\n\n    def len(self):\n        return len(self.event_ids)\n\n    def get(self, idx):\n        event_id = self.event_ids[idx]\n        event = self.batch_df.loc[event_id]\n\n        event = pd.merge(event, self.sensor_df, on=\"sensor_id\")\n\n        x = event[[\"x\", \"y\", \"z\", \"time\", \"charge\", \"qe\", \"auxiliary\"]].values\n        x = torch.tensor(x, dtype=torch.float32)\n        data = Data(x=x, n_pulses=torch.tensor(x.shape[0], dtype=torch.int32))\n\n        # Add ice transparency data\n        z = data.x[:, 2].numpy()\n        scattering = torch.tensor(self.f_scattering(z), dtype=torch.float32).view(-1, 1)\n        # absorption = torch.tensor(self.f_absorption(z), dtype=torch.float32).view(-1, 1)\n\n        data.x = torch.cat([data.x, scattering], dim=1)\n\n        # Downsample the large events\n        if data.n_pulses > self.pulse_limit:\n            data.x = data.x[np.random.choice(data.n_pulses, self.pulse_limit)]\n            data.n_pulses = torch.tensor(self.pulse_limit, dtype=torch.int32)\n\n        return data","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:38.007830Z","iopub.execute_input":"2023-03-21T05:09:38.008203Z","iopub.status.idle":"2023-03-21T05:09:38.021874Z","shell.execute_reply.started":"2023-03-21T05:09:38.008165Z","shell.execute_reply":"2023-03-21T05:09:38.020761Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# preprocessing.py\ndef prepare_sensors():\n    sensors = pd.read_csv(INPUT_PATH / \"sensor_geometry.csv\").astype(\n        {\n            \"sensor_id\": np.int16,\n            \"x\": np.float32,\n            \"y\": np.float32,\n            \"z\": np.float32,\n        }\n    )\n    sensors[\"string\"] = 0\n    sensors[\"qe\"] = 1\n\n    for i in range(len(sensors) // 60):\n        start, end = i * 60, (i * 60) + 60\n        sensors.loc[start:end, \"string\"] = i\n\n        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n        if i in range(78, 86):\n            start_veto, end_veto = i * 60, (i * 60) + 10\n            start_core, end_core = end_veto + 1, (i * 60) + 60\n            sensors.loc[start_core:end_core, \"qe\"] = 1.35\n\n    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n    sensors[\"x\"] /= 500\n    sensors[\"y\"] /= 500\n    sensors[\"z\"] /= 500\n    sensors[\"qe\"] -= 1.25\n    sensors[\"qe\"] /= 0.25\n\n    return sensors","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:38.023396Z","iopub.execute_input":"2023-03-21T05:09:38.024456Z","iopub.status.idle":"2023-03-21T05:09:38.033990Z","shell.execute_reply.started":"2023-03-21T05:09:38.024417Z","shell.execute_reply":"2023-03-21T05:09:38.032980Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# tta.py\nclass TTAWrapper(nn.Module):\n    def __init__(\n        self,\n        model,\n        device,\n        angles=[0, 180],\n    ):\n        super().__init__()\n        self.model = model\n        self.device = device\n        self.angles = [a * np.pi / 180 for a in angles]\n        self.rmats = [self.rotz(a) for a in self.angles]\n\n    def rotz(self, theta):\n        # Counter clockwise rotation\n        return (\n            torch.tensor(\n                [\n                    [np.cos(theta), -np.sin(theta), 0],\n                    [np.sin(theta), np.cos(theta), 0],\n                    [0, 0, 1],\n                ],\n                dtype=torch.float32,\n            )\n            .unsqueeze(0)\n            .to(self.device)\n        )\n\n    def forward(self, data):\n        azi_out_sin, azi_out_cos, zen_out = 0, 0, 0\n        data_rot = data\n\n        for a, mat in zip(self.angles, self.rmats):\n            data_rot.x[:, :3] = torch.matmul(data.x[:, :3], mat)\n            a_out, z_out = self.model(data_rot)\n\n            # Remove rotation from the azimuth prediction\n            azi_out_sin += torch.sin(a_out + a)\n            azi_out_cos += torch.cos(a_out + a)\n            zen_out += z_out\n\n        # https://en.wikipedia.org/wiki/Circular_mean\n        azi_out = torch.atan2(azi_out_sin, azi_out_cos)\n        zen_out /= len(self.angles)\n\n        return azi_out, zen_out","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:38.037913Z","iopub.execute_input":"2023-03-21T05:09:38.038326Z","iopub.status.idle":"2023-03-21T05:09:38.049410Z","shell.execute_reply.started":"2023-03-21T05:09:38.038297Z","shell.execute_reply":"2023-03-21T05:09:38.047507Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def infer(model, dataset, batch_size=32, device=\"cuda\"):\n    model.to(device)\n    model.eval()\n    model = TTAWrapper(model, device)\n    loader = DataLoader(dataset, batch_size=batch_size, num_workers=2)\n\n    predictions = []\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            pred_azi, pred_zen = model(batch)\n            pred_angles = torch.stack([pred_azi[:, 0], pred_zen[:, 0]], dim=1)\n            predictions.append(pred_angles.cpu())\n\n    return torch.cat(predictions, 0)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:38.050804Z","iopub.execute_input":"2023-03-21T05:09:38.051688Z","iopub.status.idle":"2023-03-21T05:09:38.060696Z","shell.execute_reply.started":"2023-03-21T05:09:38.051651Z","shell.execute_reply":"2023-03-21T05:09:38.060051Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def make_predictions(dataset_paths, device=\"cuda\", suffix=\"metric\", mode=\"test\"):\n    mpaths = []\n    for p in dataset_paths:\n        mpaths.append(sorted(list(p.rglob(f\"*{suffix}.ckpt\"))))\n\n    num_models = len([item for sublist in mpaths for item in sublist])\n    print(f\"{num_models} models found.\")\n\n    sensors = prepare_sensors()\n    # sensors[\"sensor_id\"] = sensors[\"sensor_id\"].astype(np.int16)\n    # sensors = pls.from_pandas(sensors)\n\n    meta = pd.read_parquet(\n        INPUT_PATH / f\"{mode}_meta.parquet\", columns=[\"batch_id\", \"event_id\"]\n    ).astype(_dtype)\n    batch_ids = meta[\"batch_id\"].unique()\n    output = 0\n\n    if mode == \"train\":\n        batch_ids = batch_ids[:6]\n\n    # for i, group in enumerate(mpaths):\n    #     for j, p in enumerate(group):\n\n    p = mpaths[0][0]\n    model = IceCubeModel.load_from_checkpoint(p, strict=False)\n    pre_transform = KNNGraphBuilder(nb_nearest_neighbours=8)\n\n    batch_preds = []\n    for b in batch_ids:\n        event_ids = meta[meta[\"batch_id\"] == b][\"event_id\"].tolist()\n        dataset = IceCubeSubmissionDataset(\n            b, event_ids, sensors, mode=mode, pre_transform=pre_transform\n        )\n        batch_preds.append(infer(model, dataset, device=device, batch_size=1024))\n        print(\"Finished batch\", b)\n\n        if mode == \"train\" and b == 6:\n            break\n\n    output += torch.cat(batch_preds, 0)\n\n    # After looping through folds\n    output /= num_models\n\n    event_id_labels = []\n    for b in batch_ids:\n        event_id_labels.extend(meta[meta[\"batch_id\"] == b][\"event_id\"].tolist())\n\n    sub = {\n        \"event_id\": event_id_labels,\n        \"azimuth\": output[:, 0],\n        \"zenith\": output[:, 1],\n    }\n\n    sub = pd.DataFrame(sub)\n    sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:38.063181Z","iopub.execute_input":"2023-03-21T05:09:38.063999Z","iopub.status.idle":"2023-03-21T05:09:38.077237Z","shell.execute_reply.started":"2023-03-21T05:09:38.063959Z","shell.execute_reply":"2023-03-21T05:09:38.076279Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(48, workers=True)\n\nmodel_folders = [\n        \"20230131-084311\",\n]\n\nif KERNEL:\n    dataset_paths = [Path(f\"../input/icecube-{f}\") for f in model_folders]\nelse:\n    dataset_paths = [OUTPUT_PATH / f for f in model_folders]\n\npredictions = make_predictions(dataset_paths, mode=\"test\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:38.078540Z","iopub.execute_input":"2023-03-21T05:09:38.079789Z","iopub.status.idle":"2023-03-21T05:09:45.906216Z","shell.execute_reply.started":"2023-03-21T05:09:38.079754Z","shell.execute_reply":"2023-03-21T05:09:45.904054Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"1 models found.\nFinished batch 661\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T05:09:45.910105Z","iopub.execute_input":"2023-03-21T05:09:45.910448Z","iopub.status.idle":"2023-03-21T05:09:45.930641Z","shell.execute_reply.started":"2023-03-21T05:09:45.910413Z","shell.execute_reply":"2023-03-21T05:09:45.929444Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   event_id   azimuth    zenith\n0      2092  0.373649  1.443410\n1      7344 -2.943566  2.479633\n2      9482 -1.770668  1.553747","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event_id</th>\n      <th>azimuth</th>\n      <th>zenith</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2092</td>\n      <td>0.373649</td>\n      <td>1.443410</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7344</td>\n      <td>-2.943566</td>\n      <td>2.479633</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9482</td>\n      <td>-1.770668</td>\n      <td>1.553747</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}